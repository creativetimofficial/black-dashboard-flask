{"version":3,"sources":["src/common.speech/ConversationServiceRecognizer.ts"],"names":[],"mappings":"AAAA,OAAO,EAAE,YAAY,EAAE,MAAM,mBAAmB,CAAC;AACjD,OAAO,EACH,qBAAqB,EACrB,kBAAkB,EAIlB,UAAU,EAEV,uBAAuB,EAC1B,MAAM,gBAAgB,CAAC;AACxB,OAAO,EAGH,eAAe,EACf,kBAAkB,EAGlB,gBAAgB,EAChB,qBAAqB,EAGxB,MAAM,WAAW,CAAC;AACnB,OAAO,EAAE,uBAAuB,EAAE,MAAM,oCAAoC,CAAC;AAE7E,qBAAa,6BAA8B,SAAQ,qBAAqB;gBAGhE,cAAc,EAAE,eAAe,EAC/B,iBAAiB,EAAE,kBAAkB,EACrC,WAAW,EAAE,YAAY,EACzB,gBAAgB,EAAE,gBAAgB,EAClC,UAAU,EAAE,UAAU;IAM1B,SAAS,CAAC,2BAA2B,CAAC,iBAAiB,EAAE,uBAAuB,GAAG,OAAO,CAAC,OAAO,CAAC;IAKnG,SAAS,CAAC,wBAAwB,CAAC,MAAM,EAAE,uBAAuB,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,GAAG,IAAI;IAO5G,SAAS,CAAC,yBAAyB,CAAC,MAAM,EAAE,uBAAuB,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,GAAG,IAAI;cAO/F,qBAAqB,CAAC,iBAAiB,EAAE,uBAAuB,GAAG,OAAO,CAAC,OAAO,CAAC;IAsBnG,SAAS,CAAC,iBAAiB,CACvB,SAAS,EAAE,MAAM,EACjB,SAAS,EAAE,MAAM,EACjB,kBAAkB,EAAE,kBAAkB,EACtC,SAAS,EAAE,qBAAqB,EAChC,KAAK,EAAE,MAAM,GAAG,IAAI;cASR,kBAAkB,CAAC,QAAQ,EAAE,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC;IA8DnE,SAAS,CAAC,sBAAsB,CAAC,QAAQ,EAAE,MAAM,GAAG,IAAI;CAuB3D","file":"ConversationServiceRecognizer.d.ts","sourcesContent":["import { IAudioSource } from \"../common/Exports\";\r\nimport {\r\n    CancellationErrorCode,\r\n    CancellationReason,\r\n    OutputFormat,\r\n    PropertyCollection,\r\n    PropertyId,\r\n    Recognizer,\r\n    ResultReason,\r\n    SpeechRecognitionResult\r\n} from \"../sdk/Exports\";\r\nimport {\r\n    DetailedSpeechPhrase,\r\n    EnumTranslation,\r\n    IAuthentication,\r\n    IConnectionFactory,\r\n    OutputFormatPropertyName,\r\n    RecognitionStatus,\r\n    RecognizerConfig,\r\n    ServiceRecognizerBase,\r\n    SimpleSpeechPhrase,\r\n    SpeechHypothesis\r\n} from \"./Exports\";\r\nimport { SpeechConnectionMessage } from \"./SpeechConnectionMessage.Internal\";\r\n\r\nexport class ConversationServiceRecognizer extends ServiceRecognizerBase {\r\n\r\n    public constructor(\r\n        authentication: IAuthentication,\r\n        connectionFactory: IConnectionFactory,\r\n        audioSource: IAudioSource,\r\n        recognizerConfig: RecognizerConfig,\r\n        recognizer: Recognizer) {\r\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\r\n        this.handleSpeechPhraseMessage = async (textBody: string): Promise<void> => this.handleSpeechPhrase(textBody);\r\n        this.handleSpeechHypothesisMessage = (textBody: string): void => this.handleSpeechHypothesis(textBody);\r\n    }\r\n\r\n    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage): Promise<boolean> {\r\n        void connectionMessage;\r\n        return;\r\n    }\r\n\r\n    protected handleRecognizedCallback(result: SpeechRecognitionResult, offset: number, sessionId: string): void {\r\n        void result;\r\n        void offset;\r\n        void sessionId;\r\n        return;\r\n    }\r\n\r\n    protected handleRecognizingCallback(result: SpeechRecognitionResult, duration: number, sessionId: string): void {\r\n        void result;\r\n        void duration;\r\n        void sessionId;\r\n        return;\r\n    }\r\n\r\n    protected async processSpeechMessages(connectionMessage: SpeechConnectionMessage): Promise<boolean> {\r\n        let processed: boolean = false;\r\n        switch (connectionMessage.path.toLowerCase()) {\r\n            case \"speech.hypothesis\":\r\n            case \"speech.fragment\":\r\n                if (!!this.handleSpeechHypothesisMessage) {\r\n                    this.handleSpeechHypothesisMessage(connectionMessage.textBody);\r\n                }\r\n                processed = true;\r\n                break;\r\n            case \"speech.phrase\":\r\n                if (!!this.handleSpeechPhraseMessage) {\r\n                    await this.handleSpeechPhraseMessage(connectionMessage.textBody);\r\n                }\r\n                processed = true;\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n        return processed;\r\n    }\r\n\r\n    protected cancelRecognition(\r\n        sessionId: string,\r\n        requestId: string,\r\n        cancellationReason: CancellationReason,\r\n        errorCode: CancellationErrorCode,\r\n        error: string): void {\r\n            // Implementing to allow inheritance\r\n            void sessionId;\r\n            void requestId;\r\n            void cancellationReason;\r\n            void errorCode;\r\n            void error;\r\n        }\r\n\r\n    protected async handleSpeechPhrase(textBody: string): Promise<void> {\r\n\r\n        const simple: SimpleSpeechPhrase = SimpleSpeechPhrase.fromJSON(textBody);\r\n        const resultReason: ResultReason = EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\r\n        let result: SpeechRecognitionResult;\r\n        const resultProps: PropertyCollection = new PropertyCollection();\r\n        resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);\r\n        const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;\r\n        let offset = simpleOffset;\r\n\r\n        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\r\n\r\n        if (ResultReason.Canceled === resultReason) {\r\n            const cancelReason: CancellationReason = EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\r\n            const cancellationErrorCode: CancellationErrorCode = EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\r\n\r\n            await this.cancelRecognitionLocal(\r\n                cancelReason,\r\n                cancellationErrorCode,\r\n                EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\r\n\r\n        } else {\r\n            if (!(this.privRequestSession.isSpeechEnded && resultReason === ResultReason.NoMatch && simple.RecognitionStatus !== RecognitionStatus.InitialSilenceTimeout)) {\r\n                if (this.privRecognizerConfig.parameters.getProperty(OutputFormatPropertyName) === OutputFormat[OutputFormat.Simple]) {\r\n                    result = new SpeechRecognitionResult(\r\n                        this.privRequestSession.requestId,\r\n                        resultReason,\r\n                        simple.DisplayText,\r\n                        simple.Duration,\r\n                        simpleOffset,\r\n                        simple.Language,\r\n                        simple.LanguageDetectionConfidence,\r\n                        simple.SpeakerId,\r\n                        undefined,\r\n                        textBody,\r\n                        resultProps);\r\n                } else {\r\n                    const detailed: DetailedSpeechPhrase = DetailedSpeechPhrase.fromJSON(textBody);\r\n                    const totalOffset: number = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\r\n                    const offsetCorrectedJson: string = detailed.getJsonWithCorrectedOffsets(totalOffset);\r\n\r\n                    result = new SpeechRecognitionResult(\r\n                        this.privRequestSession.requestId,\r\n                        resultReason,\r\n                        detailed.Text,\r\n                        detailed.Duration,\r\n                        totalOffset,\r\n                        detailed.Language,\r\n                        detailed.LanguageDetectionConfidence,\r\n                        detailed.SpeakerId,\r\n                        undefined,\r\n                        offsetCorrectedJson,\r\n                        resultProps);\r\n\r\n                        offset = result.offset;\r\n                }\r\n\r\n                this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);\r\n            }\r\n        }\r\n    }\r\n\r\n    protected handleSpeechHypothesis(textBody: string): void {\r\n        const hypothesis: SpeechHypothesis = SpeechHypothesis.fromJSON(textBody);\r\n        const offset: number = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\r\n        const resultProps: PropertyCollection = new PropertyCollection();\r\n        resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);\r\n\r\n        const result = new SpeechRecognitionResult(\r\n            this.privRequestSession.requestId,\r\n            ResultReason.RecognizingSpeech,\r\n            hypothesis.Text,\r\n            hypothesis.Duration,\r\n            offset,\r\n            hypothesis.Language,\r\n            hypothesis.LanguageDetectionConfidence,\r\n            hypothesis.SpeakerId,\r\n            undefined,\r\n            textBody,\r\n            resultProps);\r\n\r\n        this.privRequestSession.onHypothesis(offset);\r\n\r\n        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);\r\n    }\r\n}\r\n"]}