{"version":3,"sources":["src/sdk/PropertyId.ts"],"names":[],"mappings":"AAGA;;;GAGG;AACH,oBAAY,UAAU;IAElB;;;;;;OAMG;IACH,2BAA2B,IAAI;IAE/B;;;;;;OAMG;IACH,gCAAgC,IAAA;IAEhC;;;;;OAKG;IACH,8BAA8B,IAAA;IAE9B;;;;;;OAMG;IACH,gCAAgC,IAAA;IAEhC;;;OAGG;IACH,+BAA+B,IAAA;IAE/B;;;;;;OAMG;IACH,kCAAkC,IAAA;IAElC;;;;;;OAMG;IACH,8CAA8C,IAAA;IAE9C;;;;;;OAMG;IACH,wCAAwC,IAAA;IAExC;;;OAGG;IACH,2CAA2C,IAAA;IAE3C;;;;OAIG;IACH,oCAAoC,IAAA;IAEpC;;;;;OAKG;IACH,qCAAqC,KAAA;IAErC;;;;;OAKG;IACH,iCAAiC,KAAA;IAEjC;;;;;OAKG;IACH,qCAAqC,KAAA;IAErC;;;;;OAKG;IACH,qCAAqC,KAAA;IAErC;;;;OAIG;IACH,gCAAgC,KAAA;IAEhC;;;;;OAKG;IACH,oCAAoC,KAAA;IAEpC;;;;;;OAMG;IACH,gBAAgB,KAAA;IAEhB;;;OAGG;IACH,qCAAqC,KAAA;IAErC;;;OAGG;IACH,kCAAkC,KAAA;IAElC;;;OAGG;IACH,yCAAyC,KAAA;IAEzC;;;;OAIG;IACH,iDAAiD,KAAA;IAEjD;;;;;OAKG;IACH,oDAAoD,KAAA;IAEpD;;;OAGG;IACH,qDAAqD,KAAA;IAErD;;;OAGG;IACH,gCAAgC,KAAA;IAEhC;;;;OAIG;IACH,sCAAsC,KAAA;IAEtC;;;OAGG;IACH,0BAA0B,KAAA;IAE1B;;;OAGG;IACH,8BAA8B,KAAA;IAE9B;;;OAGG;IACH,sCAAsC,KAAA;IAEtC;;;OAGG;IACH,+CAA+C,KAAA;IAE/C;;;;OAIG;IACH,2BAA2B,KAAA;IAE3B;;;OAGG;IACH,+CAA+C,KAAA;IAE/C;;;OAGG;IACH,2CAA2C,KAAA;IAE3C;;;;;;;;;;;;OAYG;IACH,mCAAmC,KAAA;IAEnC;;;OAGG;IACH,0CAA0C,KAAA;IAE1C;;;;;;QAMI;IACJ,sCAAsC,KAAA;IAEtC;;;OAGG;IACH,kDAAkD,KAAA;IAElD;;;;OAIG;IACH,qCAAqC,KAAA;IAErC;;;;OAIG;IACH,0CAA0C,KAAA;IAE1C;;;OAGG;IACH,gDAAgD,KAAA;IAEhD;;;OAGG;IACH,kDAAkD,KAAA;IAElD;;;OAGG;IACH,wCAAwC,KAAA;IAExC;;;OAGG;IACH,2DAA2D,KAAA;IAE3D;;;;OAIG;IACH,yCAAyC,KAAA;IAEzC;;;;OAIG;IACH,gDAAgD,KAAA;IAEhD;;;;OAIG;IACH,6CAA6C,KAAA;IAE7C;;;OAGG;IACH,0BAA0B,KAAA;IAE1B;;;OAGG;IACH,uBAAuB,KAAA;IAEvB;;;OAGG;IACH,oCAAoC,KAAA;IAEpC;;;OAGG;IACH,oBAAoB,KAAA;IAEpB;;;OAGG;IACH,4BAA4B,KAAA;IAE5B;;;OAGG;IACH,wCAAwC,KAAA;IAExC;;;;OAIG;IACH,qCAAqC,KAAA;IAErC;;;;OAIG;IACH,wCAAwC,KAAA;IAExC;;;;OAIG;IACH,gCAAgC,KAAA;IAEhC;;;OAGG;IACH,4BAA4B,KAAA;IAE5B;;OAEG;IACH,2BAA2B,KAAA;IAE3B;;;OAGG;IACH,2BAA2B,KAAA;IAE3B;;;OAGG;IACH,oCAAoC,KAAA;IAEpC;;;;OAIG;IACH,4BAA4B,KAAA;IAE5B;;;;;;OAMG;IACH,qCAAqC,KAAA;IAErC;;;;OAIG;IACH,qCAAqC,KAAA;IAErC;;;;OAIG;IACH,mCAAmC,KAAA;IAEnC;;;;;;OAMG;IACH,oCAAoC,KAAA;IAEpC;;;;OAIG;IACH,4BAA4B,KAAA;IAE5B;;;;OAIG;IACH,8BAA8B,KAAA;IAE9B;;;OAGG;IACH,8BAA8B,KAAA;CACjC","file":"PropertyId.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\n/**\r\n * Defines speech property ids.\r\n * @class PropertyId\r\n */\r\nexport enum PropertyId {\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\r\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]].\r\n     * @member PropertyId.SpeechServiceConnection_Key\r\n     */\r\n    SpeechServiceConnection_Key = 0,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromEndpoint]].\r\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\r\n     * @member PropertyId.SpeechServiceConnection_Endpoint\r\n     */\r\n    SpeechServiceConnection_Endpoint,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\r\n     * use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\r\n     * @member PropertyId.SpeechServiceConnection_Region\r\n     */\r\n    SpeechServiceConnection_Region,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\r\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\r\n     * @member PropertyId.SpeechServiceAuthorization_Token\r\n     */\r\n    SpeechServiceAuthorization_Token,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization type. Currently unused.\r\n     * @member PropertyId.SpeechServiceAuthorization_Type\r\n     */\r\n    SpeechServiceAuthorization_Type,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.endpointId]].\r\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\r\n     * @member PropertyId.SpeechServiceConnection_EndpointId\r\n     */\r\n    SpeechServiceConnection_EndpointId,\r\n\r\n    /**\r\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\r\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\r\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\r\n     */\r\n    SpeechServiceConnection_TranslationToLanguages,\r\n\r\n    /**\r\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\r\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\r\n     */\r\n    SpeechServiceConnection_TranslationVoice,\r\n\r\n    /**\r\n     * Translation features.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\r\n     */\r\n    SpeechServiceConnection_TranslationFeatures,\r\n\r\n    /**\r\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[LanguageUnderstandingModel]].\r\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\r\n     */\r\n    SpeechServiceConnection_IntentRegion,\r\n\r\n    /**\r\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyHostName,\r\n\r\n    /**\r\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPort,\r\n\r\n    /**\r\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyUserName,\r\n\r\n    /**\r\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPassword,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * @member PropertyId.SpeechServiceConnection_RecoMode\r\n     */\r\n    SpeechServiceConnection_RecoMode,\r\n\r\n    /**\r\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\r\n     * directly.\r\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\r\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\r\n     */\r\n    SpeechServiceConnection_RecoLanguage,\r\n\r\n    /**\r\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\r\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead use [[SessionEventArgs.sessionId]].\r\n     * @member PropertyId.Speech_SessionId\r\n     */\r\n    Speech_SessionId,\r\n\r\n    /**\r\n     * The spoken language to be synthesized (e.g. en-US)\r\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\r\n     */\r\n    SpeechServiceConnection_SynthLanguage,\r\n\r\n    /**\r\n     * The name of the TTS voice to be used for speech synthesis\r\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\r\n     */\r\n    SpeechServiceConnection_SynthVoice,\r\n\r\n    /**\r\n     * The string to specify TTS output audio format\r\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\r\n     */\r\n    SpeechServiceConnection_SynthOutputFormat,\r\n\r\n    /**\r\n     * The list of comma separated languages used as possible source languages\r\n     * Added in version 1.13.0\r\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\r\n     */\r\n    SpeechServiceConnection_AutoDetectSourceLanguages,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\r\n     * to use this property directly.\r\n     * Instead use [[SpeechConfig.outputFormat]].\r\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestDetailedResultTrueFalse,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\r\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestProfanityFilterTrueFalse,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\r\n     * @member PropertyId.SpeechServiceResponse_JsonResult\r\n     */\r\n    SpeechServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\r\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\r\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\r\n     */\r\n    SpeechServiceResponse_JsonErrorDetails,\r\n\r\n    /**\r\n     * The cancellation reason. Currently unused.\r\n     * @member PropertyId.CancellationDetails_Reason\r\n     */\r\n    CancellationDetails_Reason,\r\n\r\n    /**\r\n     * The cancellation text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonText\r\n     */\r\n    CancellationDetails_ReasonText,\r\n\r\n    /**\r\n     * The Cancellation detailed text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\r\n     */\r\n    CancellationDetails_ReasonDetailedText,\r\n\r\n    /**\r\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\r\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\r\n     */\r\n    LanguageUnderstandingServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The URL string built from speech configuration.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * NOTE: Added in version 1.7.0.\r\n     */\r\n    SpeechServiceConnection_Url,\r\n\r\n    /**\r\n     * The initial silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_InitialSilenceTimeoutMs,\r\n\r\n    /**\r\n     * The end silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EndSilenceTimeoutMs,\r\n\r\n    /**\r\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\r\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\r\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\r\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\r\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\r\n     * behavior should be thoroughly validated as intended.\r\n     *\r\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\r\n     * https://aka.ms/csspeech/timeouts.\r\n     *\r\n     * Added in version 1.21.0.\r\n     */\r\n    Speech_SegmentationSilenceTimeoutMs,\r\n\r\n    /**\r\n     * A boolean value specifying whether audio logging is enabled in the service or not.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EnableAudioLogging,\r\n\r\n    /**\r\n     * The speech service connection language identifier mode.\r\n     * Can be \"AtStart\" (the default), or \"Continuous\". See Language\r\n     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\r\n     * for more details.\r\n     * Added in 1.25.0\r\n     **/\r\n    SpeechServiceConnection_LanguageIdMode,\r\n\r\n    /**\r\n     * A string value representing the desired endpoint version to target for Speech Recognition.\r\n     * Added in version 1.21.0\r\n     */\r\n    SpeechServiceConnection_RecognitionEndpointVersion,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity setting.\r\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_ProfanityOption,\r\n\r\n    /**\r\n     * A string value specifying which post processing option should be used by service.\r\n     * Allowed values are \"TrueText\".\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_PostProcessingOption,\r\n\r\n    /**\r\n     * A boolean value specifying whether to include word-level timestamps in the response result.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_RequestWordLevelTimestamps,\r\n\r\n    /**\r\n     * The number of times a word has to be in partial results to be returned.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_StablePartialResultThreshold,\r\n\r\n    /**\r\n     * A string value specifying the output format option in the response result. Internal use only.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_OutputFormatOption,\r\n\r\n    /**\r\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_TranslationRequestStablePartialResult,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request WordBoundary events.\r\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestWordBoundary,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\r\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestPunctuationBoundary,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\r\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestSentenceBoundary,\r\n\r\n    /**\r\n     * Identifier used to connect to the backend service.\r\n     * @member PropertyId.Conversation_ApplicationId\r\n     */\r\n    Conversation_ApplicationId,\r\n\r\n    /**\r\n     * Type of dialog backend to connect to.\r\n     * @member PropertyId.Conversation_DialogType\r\n     */\r\n    Conversation_DialogType,\r\n\r\n    /**\r\n     * Silence timeout for listening\r\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\r\n     */\r\n    Conversation_Initial_Silence_Timeout,\r\n\r\n    /**\r\n     * From Id to add to speech recognition activities.\r\n     * @member PropertyId.Conversation_From_Id\r\n     */\r\n    Conversation_From_Id,\r\n\r\n    /**\r\n     * ConversationId for the session.\r\n     * @member PropertyId.Conversation_Conversation_Id\r\n     */\r\n    Conversation_Conversation_Id,\r\n\r\n    /**\r\n     * Comma separated list of custom voice deployment ids.\r\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\r\n     */\r\n    Conversation_Custom_Voice_Deployment_Ids,\r\n\r\n    /**\r\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\r\n     * @member PropertyId.Conversation_Speech_Activity_Template\r\n     * Added in version 1.10.0.\r\n     */\r\n    Conversation_Speech_Activity_Template,\r\n\r\n    /**\r\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\r\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\r\n     * Added in version 1.15.0.\r\n     */\r\n    Conversation_Request_Bot_Status_Messages,\r\n\r\n    /**\r\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\r\n     * channel authentication.\r\n     * Added in version 1.15.1.\r\n     */\r\n    Conversation_Agent_Connection_Id,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromHost]].\r\n     */\r\n    SpeechServiceConnection_Host,\r\n\r\n    /**\r\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\r\n     */\r\n    ConversationTranslator_Host,\r\n\r\n    /**\r\n     * Optionally set the the host's display name.\r\n     * Used when joining a conversation.\r\n     */\r\n    ConversationTranslator_Name,\r\n\r\n    /**\r\n     * Optionally set a value for the X-CorrelationId request header.\r\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\r\n     */\r\n    ConversationTranslator_CorrelationId,\r\n\r\n    /**\r\n     * Set the conversation token to be sent to the speech service. This enables the\r\n     * service to service call from the speech service to the Conversation Translator service for relaying\r\n     * recognitions. For internal use.\r\n     */\r\n    ConversationTranslator_Token,\r\n\r\n    /**\r\n     * The reference text of the audio for pronunciation evaluation.\r\n     * For this and the following pronunciation assessment parameters, see\r\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_ReferenceText,\r\n\r\n    /**\r\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_GradingSystem,\r\n\r\n    /**\r\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Granularity,\r\n\r\n    /**\r\n     * Defines if enable miscue calculation.\r\n     * With this enabled, the pronounced words will be compared to the reference text,\r\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_EnableMiscue,\r\n\r\n    /**\r\n     * The json string of pronunciation assessment parameters\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Json,\r\n\r\n    /**\r\n     * Pronunciation assessment parameters.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Params,\r\n\r\n    /**\r\n     * Version of Speaker Recognition API to use.\r\n     * Added in version 1.18.0\r\n     */\r\n    SpeakerRecognition_Api_Version\r\n}\r\n"]}